{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVUYPmtFjaTL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yazHsXyEY_nE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bx_HBNDt2_E",
        "outputId": "2aa15324-5756-40ad-9885-f511825378c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part of speech POS\n",
        "keywords extraction"
      ],
      "metadata": {
        "id": "MlWvlJgK6Qdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Define the text for POS tagging\n",
        "text = \"At parties I usually talk to people about things they are passionate about.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract POS tags and corresponding words\n",
        "pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "\n",
        "# Print the POS tags and words\n",
        "for word, pos in pos_tags:\n",
        "    print(f\"Word: {word}, POS: {pos}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDzpCgi96XOf",
        "outputId": "50fd891d-2675-4183-c70a-bcb087d493c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Word: At, POS: ADP\n",
            "Word: parties, POS: NOUN\n",
            "Word: I, POS: PRON\n",
            "Word: usually, POS: ADV\n",
            "Word: talk, POS: VERB\n",
            "Word: to, POS: ADP\n",
            "Word: people, POS: NOUN\n",
            "Word: about, POS: ADP\n",
            "Word: things, POS: NOUN\n",
            "Word: they, POS: PRON\n",
            "Word: are, POS: AUX\n",
            "Word: passionate, POS: ADJ\n",
            "Word: about, POS: ADP\n",
            "Word: ., POS: PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPT2 prompt generation\n",
        "\n",
        "code ref: https://huggingface.co/docs/transformers/model_doc/gpt2"
      ],
      "metadata": {
        "id": "Bz5MkVbx3syJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n",
        "!python setup.py install\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa_RBEYCpQLw",
        "outputId": "acb76275-42db-4773-a19d-490c89bcf4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m952.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n",
            "python3: can't open file '/content/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT-2\n",
        "import openai\n",
        "\n",
        "# Set up your OpenAI API credentials\n",
        "openai.api_key = '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'\n",
        "\n",
        "\n",
        "# Define your prompt\n",
        "prompt = \"Explore how the main character's openness to new ideas and experiences shapes their journey\"\n",
        "\n",
        "# Set the temperature and max tokens for text generation\n",
        "temperature = 0.3\n",
        "max_tokens = 100\n",
        "\n",
        "# Generate text based on the prompt\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=temperature,\n",
        "  max_tokens=max_tokens,\n",
        "  n=1,\n",
        "  stop=None\n",
        ")\n",
        "\n",
        "# Extract the generated text from the response\n",
        "generated_text = response.choices[0].text.strip()\n",
        "\n",
        "# Print the generated text\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxDwpCav4XSZ",
        "outputId": "3b2a4e07-2b6c-474a-ece4-b503be9c35fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The main character's openness to new ideas and experiences shapes their journey in a variety of ways. By being open to new experiences, the main character is able to learn and grow in ways they would not have been able to if they had remained closed off. They are able to explore new places, meet new people, and gain a better understanding of the world around them. This newfound knowledge and understanding can help them make better decisions and take better actions throughout their journey. Additionally, the main character\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT-3\n",
        "import openai\n",
        "\n",
        "# Set up your OpenAI API credentials\n",
        "openai.api_key = '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'\n",
        "\n",
        "# Define your prompt\n",
        "prompt = \"I talk to a lot of different people at parties\"\n",
        "\n",
        "# Generate text based on the prompt\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "# Extract the generated text from the response\n",
        "generated_text = response.choices[0].text.strip()\n",
        "\n",
        "# Print the generated text\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x2F8Smi4cye",
        "outputId": "802faf82-c690-4ae9-d011-aa3dc58b4532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At parties, I usually talk to people about things they are passionate about, what they do for a living, what food or drinks they like, their hobbies or interests, what music they're into, and other interesting topics. Generally, I like to have light, friendly conversations and get to know people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU description analysis"
      ],
      "metadata": {
        "id": "03hP7zhphV4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Reference text\n",
        "reference = \"I use difficult words\"\n",
        "\n",
        "# Generated text\n",
        "generated_text = \"Auspicious, esoteric, pernicious, salubrious, circumlocution, abstemious, insouciant, effulgent, quixotic, laconic\"\n",
        "\n",
        "# Tokenize the reference and generated text\n",
        "reference_tokens = nltk.word_tokenize(reference.lower())\n",
        "generated_tokens = nltk.word_tokenize(generated_text.lower())\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = sentence_bleu([reference_tokens], generated_tokens)\n",
        "\n",
        "# Print the BLEU score\n",
        "print(\"BLEU score:\", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfKjXLoKBGcR",
        "outputId": "7839f747-4334-4dfc-a5e6-af2cb2d09a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**domain specific lexical analysis **"
      ],
      "metadata": {
        "id": "fW5fvmZ-hKS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference set of domain-specific terms\n",
        "reference_set = {\"word\", \"difficult\", \"open to experience\", ...}\n",
        "\n",
        "# Generated text\n",
        "generated_text = \"Auspicious esoteric pernicious salubrious circumlocution abstemious insouciant effulgent quixotic laconic\"\n",
        "# Tokenize the generated text into words\n",
        "generated_tokens = generated_text.lower().split()\n",
        "\n",
        "# Calculate domain-specific lexical overlap\n",
        "domain_specific_overlap = len(set(generated_tokens) & reference_set) / len(reference_set) * 100\n",
        "\n",
        "# Print the percentage of domain-specific lexical overlap\n",
        "print(\"Domain-specific lexical overlap:\", domain_specific_overlap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZMa2L1aWW03",
        "outputId": "51190fc6-4b03-4f70-a5a2-36cf4d7b26c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Domain-specific lexical overlap: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BART Prompt generation\n"
      ],
      "metadata": {
        "id": "fgNSl-xWEHrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "GD7CnHEqaM1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4100a32f-a206-4b83-8ac4-ccac1403743e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Openness to experience has both motivational and structural components People high in openness are motivated to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nsnv9M1PFtlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BART model and tokenizer\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
        "\n",
        "# Set the prompt for text generation\n",
        "prompt = \"Openness to experience has both motivational and structural components People high in openness are motivated to seek new experiences and to engage in self-examination. Structurally, they have a fluid style of consciousness that allows them to make novel associations between remotely connected ideas. Closed people by contrast are more comfortable with familiar and traditional experiences.\"\n",
        "\n",
        "# Tokenize the prompt and generate text with BART\n",
        "input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
        "output = model.generate(input_ids)\n",
        "\n",
        "# Decode the generated text and print\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6owR3yPF31B",
        "outputId": "f6c525fb-ead1-4fcb-9f31-5beca14b9c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Openness to experience has both motivational and structural components People high in openness are motivated to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# Load pre-trained BART model and tokenizer\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
        "\n",
        "# Set the input text for prompt generation\n",
        "input_text = \"The history of artificial intelligence\"\n",
        "\n",
        "# Generate the prompt using BART\n",
        "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "output = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
        "\n",
        "# Decode the generated prompt and print\n",
        "generated_prompt = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7yNrh49F4Wp",
        "outputId": "1ba0ef8c-e30a-49a2-cb96-21d46b501251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The history of artificial intelligence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n"
      ],
      "metadata": {
        "id": "gXl9t8eAGYq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "text = \"beign extroverted and out going\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)"
      ],
      "metadata": {
        "id": "NlNsppGcenqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(50)\n",
        "generator(\"extroverted and outgoing person\", max_length=30, num_return_sequences=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBookiLOfEkD",
        "outputId": "38154351-6643-436c-ec53-7049d029adbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'extroverted and outgoing person (COG) type. For those who are not COG type, this is a condition when the sender of the'},\n",
              " {'generated_text': 'extroverted and outgoing person, the brain is one that is involved in the pleasure-seeking and reward-seeking functions.\\n\\nMasking is'},\n",
              " {'generated_text': 'extroverted and outgoing person, a person whose identity is obscured from the outside eyes of the people they interact with, and a person who can neither'},\n",
              " {'generated_text': 'extroverted and outgoing person. These are people that can\\'t leave the community. That\\'s where the power is.\" I\\'m not talking about the'},\n",
              " {'generated_text': 'extroverted and outgoing person to a character, and the other part is the character from the same story. In this sense the character-line is'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5mSZxO5_fL8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}